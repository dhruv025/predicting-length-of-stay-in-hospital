# -*- coding: utf-8 -*-
"""los_hospital.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12kQdsb6AtwwJ4cHA9cdBBotyqQT2UWq-
"""

from google.colab import drive

drive.mount('/content/drive')

#pandas library is used to import dataset
import pandas as pd

import numpy as np

#importing the dataset using pandas library
df = pd.read_csv('drive/My Drive/mimic3d.csv')

#no. of rows and columns
df.shape

#this head method returns top n row of dataframe(by default 5)
df.head()

#drop method is used to remove a particular column
df = df.drop('hadm_id',axis = 1)

#updated dataset
df.head()

#no. of row and colums after updation
df.shape

#describe method is used to view some statistical details
df.describe()

#y_train is having dependent variable
y_train = df['LOSgroupNum']

y_train

#x_train are having independent variables
x_train = df.drop('LOSgroupNum',1)

x_train.shape

#Removing the columns from the x_train whose features didn't contribute to the model
x_train = x_train.drop(['LOSdays','AdmitDiagnosis','insurance','religion','marital_status','ethnicity','AdmitProcedure','ExpiredHospital'],axis=1)

x_train.shape

y_train

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
plt.style.use('ggplot')

#visualization of certain features using bar plot
df.groupby('gender').size().plot.bar()

df.groupby('admit_type').size().plot.bar()

df.groupby('admit_location').size().plot.bar()

#checking for mising values in x_train
pd.isnull(x_train).values.any()

x_train.info()

from sklearn import preprocessing

from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder

#since, we have 3 categorical values in x_train, so to convert these values to numeric we will use one hot encoding
categorical_var = ['gender','admit_type','admit_location']
for i in categorical_var:
  if i in x_train.columns:
    dummy = pd.get_dummies(x_train[i])
    x_train = x_train.drop(i,axis=1)
    x_train = pd.concat([x_train,dummy],axis=1)

#x_train after applying one hot encoding
x_train

df.shape

x_train.shape

x_not_scaled = x_train.copy()
y_not_scaled = y_train.copy()
print(x_not_scaled.shape)
print(y_not_scaled.shape)

X_not_scaled = x_not_scaled.values
Y_not_scaled = y_not_scaled.values

X_not_scaled

Y_not_scaled

#featue scaling
scaler = preprocessing.StandardScaler()

scaler.fit_transform(X_not_scaled)

scaler.fit_transform(Y_not_scaled.reshape(-1,1))

x_scaled = scaler.fit_transform(X_not_scaled)

y_scaled = scaler.fit_transform(Y_not_scaled.reshape(-1,1))

from sklearn.model_selection import train_test_split

#splitting the dataset into training(80%) and test(20%) dataset
X_train, X_test, Y_train, Y_test = train_test_split(X_not_scaled,Y_not_scaled,test_size = 0.2)

len(X_train)

len(X_test)

#Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor

#n_estimators denote no. of random trees
model = RandomForestRegressor(n_estimators=100)

model.fit(X_train,Y_train)

y_pred = model.predict(X_test)

from sklearn import metrics
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print('Mean Absolute Error:',mean_absolute_error(Y_test,y_pred))

print('Mean Squared Error:',mean_squared_error(Y_test,y_pred))

print('Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test,y_pred)))

print('r2_score:',r2_score(Y_test,y_pred))

model.predict([[35, 0.16, 2.59, 0.00, 1.30, 25.12, 43.44, 0.65, 0.05, 5.19, 14.91, 1.13, 0.65, 398.70, 493.89, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])

model.predict([[21, 0.07, 0.97, 1.04, 3.13, 62.38, 43.46, 1.88, 0.21, 18.01, 9.94, 4.10, 0.21, 1337.13, 1482.53, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])

trying different numbers of n_estimators
estimators = np.arange(10, 200, 10)
scores = []
for i in estimators:
  model.set_params(n_estimators = i)
  model.fit(X_train, Y_train)
  scores.append(model.score(X_test,Y_test))
plt.title("Effect of n_estimators")
plt.xlabel("n_estimator")
plt.ylabel("score")
plt.plot(estimators, scores)

#splitting the dataset into training(70%) and test(30%) dataset
X_train, X_test, Y_train, Y_test = train_test_split(x_scaled,Y_not_scaled,test_size = 0.3)

#Support Vector Regressor
from sklearn.svm import SVR

model = SVR(kernel='rbf')
model.fit(X_train,Y_train)

y_pred = model.predict(X_test)

y_pred

print('Mean Absolute Error:',mean_absolute_error(Y_test,y_pred))
print('Mean Squared Error:',mean_squared_error(Y_test,y_pred))
print('Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test,y_pred)))
print('r2_score:',r2_score(Y_test,y_pred))

plt.scatter(X_train[:,0], Y_train, color = 'red')
plt.plot(X_test, model.predict(X_test), color = 'blue')
plt.title('SVR Regression Model')
plt.xlabel('x-axis')
plt.ylabel('y-axis')
plt.show

#Decison Tree Regressor
from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor(random_state = 0)

model.fit(X_train,Y_train)

y_pred = model.predict(X_test)

y_pred

print('Mean Absolute Error:',mean_absolute_error(Y_test,y_pred))
print('Mean Squared Error:',mean_squared_error(Y_test,y_pred))
print('Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test,y_pred)))
print('r2_score:',r2_score(Y_test,y_pred))

#so, lets run the model against the test data
from sklearn.model_selection import cross_val_predict
fig, ax = plt.subplots()
ax.scatter(Y_test, y_pred, edgecolors = (0,0,0))
ax.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw = 3)
ax.set_xlabel('Actual')
ax.set_ylabel('Predicted')
ax.set_title('Ground Truth vs Predicted')
plt.show()

MLA = []
MLA.append(RandomForestRegressor())
MLA.append(SVR())
MLA.append(DecisionTreeRegressor())

MLA_columns = []
MLA_compare = pd.DataFrame(columns = MLA_columns)

row_index = 0
for alg in MLA:
  y_pred = alg.fit(X_train, Y_train).predict(X_test)
  MLA_name = alg.__class__.__name__
  MLA_compare.loc[row_index,'MLA Name'] = MLA_name
  MLA_compare.loc[row_index, 'Mean Absolute Error'] = mean_absolute_error(Y_test,y_pred)
  MLA_compare.loc[row_index, 'Mean Squared Error'] = mean_squared_error(Y_test,y_pred)
  MLA_compare.loc[row_index, 'Root Mean Squared Error'] = np.sqrt(mean_squared_error(Y_test,y_pred))
  MLA_compare.loc[row_index, 'r2_score'] = r2_score(Y_test,y_pred)

  row_index+=1
MLA_compare.sort_values(by = ['r2_score'], ascending = False, inplace = True)    
MLA_compare

import seaborn as sns
plt.subplots(figsize=(8,5))
sns.barplot(x = "MLA Name", y = "Mean Absolute Error", data = MLA_compare, palette = 'hot', edgecolor = sns.color_palette('dark',7))
plt.xticks(rotation = 90)
plt.title('Mean Absolute Error Comparison')
plt.show()

import seaborn as sns
plt.subplots(figsize=(8,5))
sns.barplot(x = "MLA Name", y = "Mean Squared Error", data = MLA_compare, palette = 'hot', edgecolor = sns.color_palette('dark',7))
plt.xticks(rotation = 90)
plt.title('Mean Squared Error Comparison')
plt.show()

import seaborn as sns
plt.subplots(figsize=(8,5))
sns.barplot(x = "MLA Name", y = "Root Mean Squared Error", data = MLA_compare, palette = 'hot', edgecolor = sns.color_palette('dark',7))
plt.xticks(rotation = 90)
plt.title('Root Mean Squared Error Comparison')
plt.show()

import seaborn as sns
plt.subplots(figsize=(8,5))
sns.barplot(x = "MLA Name", y = "r2_score", data = MLA_compare, palette = 'hot', edgecolor = sns.color_palette('dark',7))
plt.xticks(rotation = 90)
plt.title('r2_score Comparison')
plt.show()